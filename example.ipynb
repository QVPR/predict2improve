{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4396e98d-0aed-453a-803f-bc540ed65a90",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "This notebook shows an example code segment from our work published in \"Predicting to Improve: Integrity Measures for Assessing Visual Localization Performance\".\n",
    "\n",
    "Our supervised learning approach requires a calibration dataset (reference and query set) for training, and a separate dataset (reference and query set) for testing. Ground truth data is required for the calibration set for training, and for the test set to assess performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f938c8-5d22-4d42-8882-a0233309bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from vpred_tools import *\n",
    "from vpred_factors import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a9d0a-c571-40a6-857d-913e310c90a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, we use feature vectors extracted from the Nordland fall set as our reference set, and from the spring set as our query set.  The calibration and test sets are taken from geographically different sections of the dataset.\n",
    "\n",
    "Our example feature vectors have been created by first pre-processing our images by converting to grayscale, downsampling to 64x64, and patch-normalizing, and then using Sum of Absolute Differences (SAD) to form the feature vectors. Examples of our feature vectors are shown below (reshaped as an image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c8daa-1beb-4a85-8db3-1cbf12b8ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('compressed_features.npz') as data:\n",
    "    features_calref = data['features_calref']\n",
    "    features_calqry = data['features_calqry']\n",
    "    features_testref = data['features_testref']\n",
    "    features_testqry = data['features_testqry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca9f81-f2b4-43d2-877c-64b762953eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,6))\n",
    "ax[0].imshow(features_calref[0].reshape((64,64)),cmap='gray'); ax[0].axis('off')\n",
    "ax[1].imshow(features_calqry[0].reshape((64,64)),cmap='gray'); ax[1].axis('off')\n",
    "ax[0].set_title('First reference image (Fall)'); \n",
    "ax[1].set_title('First query image (Spring)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0bc11-43d3-4ca0-9761-da3c215373e9",
   "metadata": {},
   "source": [
    "In this example, the reference and query images are taken at the same locations, so the ground truth match for each query is the reference image with the same index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08070cb-893c-4520-8961-3e7c0071788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ground truth\n",
    "actual_match_cal=np.arange(0,len(features_calqry))\n",
    "actual_match=np.arange(0,len(features_testqry))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a359a0f-cf94-4a4c-b290-54dd0477ae57",
   "metadata": {},
   "source": [
    "We create the similarity matrix for the calibration set and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d154644-1047-43a7-b342-37a221b6af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scal,_,_=create_normalised_similarity_matrix(features_calref,features_calqry)\n",
    "S,Srefmean,Srefstd=create_normalised_similarity_matrix(features_testref,features_testqry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8442a48-eba9-4e3b-a9dd-594569c312d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,6))\n",
    "ax[0].imshow(Scal); ax[1].imshow(S);\n",
    "ax[0].set_title('Calibration Set Distance Matrix'); \n",
    "ax[1].set_title('Test Set Distance Matrix');\n",
    "for axes in ax:\n",
    "    axes.set_xlabel('query frame'); axes.set_ylabel('reference frame');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765294f9-03c4-44a1-a59e-2ad83dcefe55",
   "metadata": {},
   "source": [
    "## Supervised learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8619093-f3c2-44ae-97af-f163448b37fe",
   "metadata": {},
   "source": [
    "We define the acceptable tolerance for a 'correct' match as +/- one image frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ade56-3906-4c71-a1ac-77ebe6cbc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacabdb-298d-488c-bfe9-5a6afa6df1ec",
   "metadata": {},
   "source": [
    "Train the Support Vector Machine using the calibration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919844e1-ae9e-4357-a524-442bc039fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract factors that describe the \"sharpness\" of distance vectors\n",
    "factor1_cal=find_va_factor(Scal)\n",
    "factor2_cal=find_grad_factor(Scal)\n",
    "factors = ['VA ratio','Average Gradient'] # for axis labels when plotting\n",
    "# Form input vector\n",
    "Xcal=np.c_[factor1_cal,factor2_cal]\n",
    "scaler = StandardScaler()\n",
    "Xcal_scaled = scaler.fit_transform(Xcal)\n",
    "# Form desired output vector\n",
    "y_cal=find_y(Scal,actual_match_cal,tolerance)\n",
    "# Define and train the Support Vector Machine\n",
    "model = svm.SVC(kernel='rbf',C=1,gamma='scale',class_weight='balanced')\n",
    "model.fit(Xcal_scaled,y_cal);\n",
    "# Make predictions on calibration set to assess performance\n",
    "y_pred_cal = model.predict(Xcal_scaled)\n",
    "y_zvalues_cal = model.decision_function(Xcal_scaled)\n",
    "print('Performance of prediction on Calibration set: ')\n",
    "find_prediction_performance_metrics(y_pred_cal,y_cal,verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750158c-2d3e-4b4c-ac63-749c31db6c19",
   "metadata": {},
   "source": [
    "Make predictions on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d55eb-eb1f-40aa-bd0f-49e7cddc59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract factors from similarity matrix on test set\n",
    "factor1=find_va_factor(S)\n",
    "factor2=find_grad_factor(S)\n",
    "# Form SVM input vector\n",
    "X=np.c_[factor1,factor2]\n",
    "X_scaled=scaler.transform(X)\n",
    "# Make predictions\n",
    "y_zvalues = model.decision_function(X_scaled)\n",
    "y_pred = model.predict(X_scaled)\n",
    "\n",
    "# Assess performance of prediction on test set\n",
    "y=find_y(S,actual_match,tolerance) # find acutal performance of test set\n",
    "print('Performance of prediction on Test set: ')\n",
    "find_prediction_performance_metrics(y_pred,y,verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516434e7-b84c-4e51-a18e-2dc12f452ea4",
   "metadata": {},
   "source": [
    "Now we extract metrics for plotting and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01ac2f-aa3b-4b4f-9797-77a7b219c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_p,bl_r,bl_tp,bl_fp,bl_tn,bl_fn,bl_d=find_baseline_performance_metrics(S,actual_match,tolerance)\n",
    "cl_p,cl_r,cl_tp,cl_fp,cl_tn,cl_fn,cl_d=find_closedloop_performance_metrics(S,actual_match,tolerance,y_pred)\n",
    "\n",
    "plot_baseline_vs_closedloop_PRcurves(S,actual_match,tolerance,y_pred)\n",
    "plt.title('Test Set: Baseline vs Closed-Loop Performance');\n",
    "plt.xlim([0,0.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3cd4f-fa02-4da2-ae40-df4084f0003d",
   "metadata": {},
   "source": [
    "We see in this example that the closed-loop prediction system provides an improvement over the baseline VPR technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
